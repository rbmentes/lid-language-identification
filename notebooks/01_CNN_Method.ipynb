{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrkZOr0rinP0",
        "outputId": "be535aef-0144-4877-ef1f-fdef1f208abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T90HBBc40nN",
        "outputId": "c99e0252-3523-4392-d435-3d54eaed5baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SadKharippB",
        "outputId": "2e635914-bb7d-4213-a2c5-66d5c022326b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "O0UsO7_GiusY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 16000\n",
        "DURATION = 3\n",
        "NUM_SAMPLES = SAMPLE_RATE * DURATION\n",
        "\n",
        "# âœ… Correct speech parameters\n",
        "N_MELS = 64\n",
        "N_FFT = 400        # 25 ms\n",
        "HOP_LENGTH = 160  # 10 ms\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LR = 5e-4\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "LANGUAGES = ['en', 'de', 'es', 'tr', 'ja']\n",
        "LABEL_MAP = {lang: i for i, lang in enumerate(LANGUAGES)}\n",
        "\n",
        "BASE_DATA = \"/content/drive/MyDrive/LID_Project/data\"\n",
        "SAVE_MEL  = \"/content/drive/MyDrive/LID_Project/logmel_3s\"\n"
      ],
      "metadata": {
        "id": "YHvsrTY8ivYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio_3s(path):\n",
        "    audio, _ = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
        "\n",
        "    if len(audio) > NUM_SAMPLES:\n",
        "        audio = audio[:NUM_SAMPLES]\n",
        "    else:\n",
        "        audio = np.pad(audio, (0, NUM_SAMPLES - len(audio)))\n",
        "\n",
        "    return audio\n"
      ],
      "metadata": {
        "id": "tnpX88X7ixEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FIXED_FRAMES = 300\n",
        "\n",
        "def extract_logmel(audio):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=audio,\n",
        "        sr=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS,\n",
        "        power=2.0\n",
        "    )\n",
        "\n",
        "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    # normalization\n",
        "    logmel = (logmel - logmel.mean()) / (logmel.std() + 1e-9)\n",
        "\n",
        "    # forced fixed time lenght\n",
        "    if logmel.shape[1] < FIXED_FRAMES:\n",
        "        pad_width = FIXED_FRAMES - logmel.shape[1]\n",
        "        logmel = np.pad(logmel, ((0, 0), (0, pad_width)))\n",
        "    else:\n",
        "        logmel = logmel[:, :FIXED_FRAMES]\n",
        "\n",
        "    return torch.tensor(logmel, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "dOZm2j-gu62f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(SAVE_MEL, exist_ok=True)\n",
        "\n",
        "MAX_PER_LANG = 3000\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    src = os.path.join(BASE_DATA, lang)\n",
        "    dst = os.path.join(SAVE_MEL, lang)\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "    files = [f for f in os.listdir(src) if f.endswith(\".wav\")]\n",
        "    files = files[:MAX_PER_LANG]  # limit\n",
        "\n",
        "    print(f\"Processing {lang}: {len(files)} files\")\n",
        "\n",
        "    for f in tqdm(files):\n",
        "        wav_path = os.path.join(src, f)\n",
        "        mel_path = os.path.join(dst, f.replace(\".wav\", \".pt\"))\n",
        "\n",
        "        if os.path.exists(mel_path):\n",
        "            continue\n",
        "\n",
        "        audio = load_audio_3s(wav_path)\n",
        "        logmel = extract_logmel(audio)\n",
        "        torch.save(logmel, mel_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApkjONgni0Mh",
        "outputId": "365c0240-e605-4481-bfd4-553788401c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing en: 3000 files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:01<00:00, 1543.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing de: 3000 files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:08<00:00, 351.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing es: 3000 files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:03<00:00, 913.63it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing tr: 3000 files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:09<00:00, 326.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ja: 3000 files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 5228.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogMelDataset(Dataset):\n",
        "    def __init__(self, base_path):\n",
        "        self.items = []\n",
        "\n",
        "        for lang in LANGUAGES:\n",
        "            folder = os.path.join(base_path, lang)\n",
        "            for f in os.listdir(folder):\n",
        "                if f.endswith(\".pt\"):\n",
        "                    self.items.append(\n",
        "                        (os.path.join(folder, f), LABEL_MAP[lang])\n",
        "                    )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.items[idx]\n",
        "        x = torch.load(path).unsqueeze(0)  # [1, 64, T]\n",
        "        return x, label\n"
      ],
      "metadata": {
        "id": "vp7fSr8Vi1yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LogMelDataset(SAVE_MEL)\n"
      ],
      "metadata": {
        "id": "FvMiJlDSZUoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_items = []\n",
        "val_items = []\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    lang_items = [item for item in dataset.items if item[1] == LABEL_MAP[lang]]\n",
        "\n",
        "    train_lang, val_lang = train_test_split(\n",
        "        lang_items,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    train_items.extend(train_lang)\n",
        "    val_items.extend(val_lang)\n"
      ],
      "metadata": {
        "id": "k--3JO5oZWIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitDataset(Dataset):\n",
        "    def __init__(self, items):\n",
        "        self.items = items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.items[idx]\n",
        "\n",
        "        x = torch.load(path)  # [64, T]\n",
        "\n",
        "        # delta features\n",
        "        delta = x[:, 1:] - x[:, :-1]\n",
        "        delta = torch.nn.functional.pad(delta, (0, 1))\n",
        "\n",
        "\n",
        "        x = torch.stack([x, delta], dim=0)  # [2, 64, T]\n",
        "\n",
        "        return x, label\n"
      ],
      "metadata": {
        "id": "5K-8y-9QhHSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = SplitDataset(train_items)\n",
        "val_set   = SplitDataset(val_items)\n"
      ],
      "metadata": {
        "id": "lNmDvbIeZbEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "8HU1yKBRZdfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_GRU_LanguageID(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(2, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),   # freq â†“\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),   # freq â†“\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # GRU for temporal modeling\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=128,\n",
        "            hidden_size=128,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * 2, 128),  # bidirectional\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 2, 64, T]\n",
        "\n",
        "        x = self.cnn(x)              # [B, 128, F, T]\n",
        "        x = x.mean(dim=2)            # average over frequency â†’ [B, 128, T]\n",
        "        x = x.permute(0, 2, 1)       # [B, T, 128]\n",
        "\n",
        "        out, _ = self.gru(x)         # [B, T, 256]\n",
        "        out = out.mean(dim=1)        # temporal average\n",
        "\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "OAA-VmHWkYSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_GRU_LanguageID().to(DEVICE)\n",
        "# class-weighted loss (stabilizes training)\n",
        "weights = torch.tensor([1.0, 1.2, 1.2, 1.3, 1.3]).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n"
      ],
      "metadata": {
        "id": "_H2P4EGzi65A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE)      # [B, 2, 64, T]\n",
        "            y = y.to(DEVICE)\n",
        "\n",
        "            T = x.shape[-1]\n",
        "            chunk_len = T // 3\n",
        "\n",
        "            votes = []\n",
        "\n",
        "            for i in range(3):\n",
        "                xs = x[:, :, :, i*chunk_len:(i+1)*chunk_len]\n",
        "                logits = model(xs)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                votes.append(preds)\n",
        "\n",
        "            votes = torch.stack(votes, dim=1)\n",
        "            final_preds, _ = torch.mode(votes, dim=1)\n",
        "\n",
        "            correct += (final_preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return 100 * correct / total\n"
      ],
      "metadata": {
        "id": "MtQ0kfnbz7U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "BEST_MODEL_PATH = \"/content/drive/MyDrive/LID_Project/best_model.pt\"\n"
      ],
      "metadata": {
        "id": "S6JJnMWT0ROd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "\n",
        "if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "    print(\"âœ… Best model saved\")\n",
        "\n",
        "print(f\"Loss: {total_loss/len(train_loader):.4f} | \"\n",
        "      f\"Val Acc: {val_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB3YbaHxi950",
        "outputId": "dd6d6e8a-ba44-4ab4-8eb2-51793934acab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [1:31:47<00:00,  3.73s/it]\n",
            "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:50<00:00, 13.42it/s]\n",
            "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:49<00:00, 13.50it/s]\n",
            "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:49<00:00, 13.48it/s]\n",
            "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:48<00:00, 13.55it/s]\n",
            "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:48<00:00, 13.59it/s]\n",
            "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:49<00:00, 13.48it/s]\n",
            "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:48<00:00, 13.56it/s]\n",
            "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:49<00:00, 13.53it/s]\n",
            "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1476/1476 [01:49<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Best model saved\n",
            "Loss: 0.5149 | Val Acc: 64.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"BEST VALIDATION ACCURACY: {best_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC0jJIXbGHUe",
        "outputId": "5ab59e1b-b59d-4fbd-adcd-ba314182bd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST VALIDATION ACCURACY: 64.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… Best model loaded for demo\")\n"
      ],
      "metadata": {
        "id": "MvqLq4H80auG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b9d317-d64a-4b66-ffff-82fcb3532920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Best model loaded for demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_demo_audio(wav_path):\n",
        "    audio = load_audio_3s(wav_path)\n",
        "    logmel = extract_logmel(audio)\n",
        "\n",
        "    # delta\n",
        "    delta = logmel[:, 1:] - logmel[:, :-1]\n",
        "    delta = torch.nn.functional.pad(delta, (0, 1))\n",
        "\n",
        "    x = torch.stack([logmel, delta], dim=0)  # [2, 64, T]\n",
        "    x = x.unsqueeze(0)  # [1, 2, 64, T]\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "VHgcOUdF0bl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_language(wav_path):\n",
        "    x = process_demo_audio(wav_path).to(DEVICE)\n",
        "\n",
        "    T = x.shape[-1]\n",
        "    chunk_len = T // 3\n",
        "\n",
        "    probs_sum = torch.zeros(len(LANGUAGES)).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(3):\n",
        "            xs = x[:, :, :, i*chunk_len:(i+1)*chunk_len]\n",
        "            logits = model(xs)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            probs_sum += probs.squeeze(0)\n",
        "\n",
        "    probs_avg = probs_sum / 3\n",
        "    pred_idx = probs_avg.argmax().item()\n",
        "\n",
        "    return LANGUAGES[pred_idx], probs_avg.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "iGg1ZSU_0k-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEMO_PATH = \"/content/drive/MyDrive/LID_Project/demo\"\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for demo_file in sorted(os.listdir(DEMO_PATH)):\n",
        "    if not demo_file.endswith(\".wav\"):\n",
        "        continue\n",
        "\n",
        "    demo_audio = os.path.join(DEMO_PATH, demo_file)\n",
        "\n",
        "    # ðŸ”¹ TRUE language from filename\n",
        "    true_lang = demo_file.split(\"_\")[0]\n",
        "\n",
        "    # ðŸ”¹ MODEL prediction\n",
        "    pred_lang, probs = predict_language(demo_audio)\n",
        "\n",
        "    # accuracy count\n",
        "    total += 1\n",
        "    if pred_lang == true_lang:\n",
        "        correct += 1\n",
        "\n",
        "    print(\"\\nðŸŽ§ Audio:\", demo_file)\n",
        "    print(\"âœ… True language:     \", true_lang)\n",
        "    print(\"ðŸ¤– Predicted language:\", pred_lang)\n",
        "    print(\"Probabilities:\")\n",
        "    for lang, p in zip(LANGUAGES, probs):\n",
        "        print(f\"  {lang}: {p:.3f}\")\n",
        "\n",
        "# ðŸ”¹ demo accuracy\n",
        "print(\"\\nðŸ“Š DEMO ACCURACY:\", 100 * correct / total, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn08KmIMIBGp",
        "outputId": "8749ffd9-6171-4dfc-bfda-16db53043ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ§ Audio: de_demo_1.wav\n",
            "âœ… True language:      de\n",
            "ðŸ¤– Predicted language: de\n",
            "Probabilities:\n",
            "  en: 0.015\n",
            "  de: 0.930\n",
            "  es: 0.046\n",
            "  tr: 0.006\n",
            "  ja: 0.003\n",
            "\n",
            "ðŸŽ§ Audio: de_demo_2.wav\n",
            "âœ… True language:      de\n",
            "ðŸ¤– Predicted language: en\n",
            "Probabilities:\n",
            "  en: 0.451\n",
            "  de: 0.098\n",
            "  es: 0.007\n",
            "  tr: 0.104\n",
            "  ja: 0.340\n",
            "\n",
            "ðŸŽ§ Audio: en_demo_1.wav\n",
            "âœ… True language:      en\n",
            "ðŸ¤– Predicted language: en\n",
            "Probabilities:\n",
            "  en: 0.921\n",
            "  de: 0.005\n",
            "  es: 0.007\n",
            "  tr: 0.052\n",
            "  ja: 0.014\n",
            "\n",
            "ðŸŽ§ Audio: en_demo_2.wav\n",
            "âœ… True language:      en\n",
            "ðŸ¤– Predicted language: en\n",
            "Probabilities:\n",
            "  en: 0.472\n",
            "  de: 0.054\n",
            "  es: 0.318\n",
            "  tr: 0.022\n",
            "  ja: 0.134\n",
            "\n",
            "ðŸŽ§ Audio: es_demo_1.wav\n",
            "âœ… True language:      es\n",
            "ðŸ¤– Predicted language: es\n",
            "Probabilities:\n",
            "  en: 0.379\n",
            "  de: 0.003\n",
            "  es: 0.586\n",
            "  tr: 0.017\n",
            "  ja: 0.015\n",
            "\n",
            "ðŸŽ§ Audio: es_demo_2.wav\n",
            "âœ… True language:      es\n",
            "ðŸ¤– Predicted language: ja\n",
            "Probabilities:\n",
            "  en: 0.009\n",
            "  de: 0.007\n",
            "  es: 0.316\n",
            "  tr: 0.064\n",
            "  ja: 0.604\n",
            "\n",
            "ðŸŽ§ Audio: ja_demo_1.wav\n",
            "âœ… True language:      ja\n",
            "ðŸ¤– Predicted language: ja\n",
            "Probabilities:\n",
            "  en: 0.194\n",
            "  de: 0.002\n",
            "  es: 0.016\n",
            "  tr: 0.052\n",
            "  ja: 0.736\n",
            "\n",
            "ðŸŽ§ Audio: ja_demo_2.wav\n",
            "âœ… True language:      ja\n",
            "ðŸ¤– Predicted language: ja\n",
            "Probabilities:\n",
            "  en: 0.094\n",
            "  de: 0.125\n",
            "  es: 0.036\n",
            "  tr: 0.070\n",
            "  ja: 0.674\n",
            "\n",
            "ðŸŽ§ Audio: tr_demo_1.wav\n",
            "âœ… True language:      tr\n",
            "ðŸ¤– Predicted language: tr\n",
            "Probabilities:\n",
            "  en: 0.281\n",
            "  de: 0.093\n",
            "  es: 0.078\n",
            "  tr: 0.433\n",
            "  ja: 0.115\n",
            "\n",
            "ðŸŽ§ Audio: tr_demo_2.wav\n",
            "âœ… True language:      tr\n",
            "ðŸ¤– Predicted language: es\n",
            "Probabilities:\n",
            "  en: 0.272\n",
            "  de: 0.140\n",
            "  es: 0.297\n",
            "  tr: 0.212\n",
            "  ja: 0.080\n",
            "\n",
            "ðŸ“Š DEMO ACCURACY: 70.0 %\n"
          ]
        }
      ]
    }
  ]
}
